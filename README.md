# Transformer-based-CNN-Approach-for-RS-Scene-Classification

Feature extraction in remote sensing is a challenging yet crucial operation for scene
classification because of cloud cover and overlapping edges present in the data. We present an
analysis of different deep learning architectures on multiple scene classification datasets, to
understand the features and weigh the advantages of one or more functional blocks (such as
convolution and attention mechanism) connected in different convolutional neural networks.
The work takes into consideration five open-source benchmark datasets: UC-Merced Land
Use, WHU-RS19, Optimal-31, RSI-CB256, and MLRSNet, that have been openly made
available to the research community. To perform this task, architectures such as VGG-16,
Resnet50, EfficientNetB3, Vision Transformers (ViT), Swin Transformers, and ConvNeXt is
used. Though the comparison between deep learning models for scene classification has been done, the
comparison between different Transformer-based architectures along with the convolutionbased architectures has not been systematically addressed in the remote sensing literature. We
have obtained a new benchmark, that exceeds the state-of-the-art results for all the datasets on
a 90:10 train-test split.

Keywords: Convolutional Neural Networks; Remote Sensing; Scene Classification; fastai

### *Paper available: Journal under review
### *Codes: Will be made available post-acceptance 
### Authors: Arrun Sivasubramanian(1), Prashanth VR(1), Theivaprakasham Hari(1), Dr. Sowmya V(1), Dr. Gopalakrishnan EA(2), Dr. Vinaykumar Ravi(3)
### Affiliation: 
(1) CEN, Amrita School of Engienering, Coimbatore, India; 
(2) Amrita School of Computing, Bangalore, Amrita Vishwa Vidyapeetham, India;
(3) Center for Artificial Intelligence, Prince Mohammed Bin Fahad University, Saudi Arabia
