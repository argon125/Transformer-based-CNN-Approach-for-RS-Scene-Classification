{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c50cee3-2c4c-4701-aebf-6b16c962d192",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.10.0+cu111)\n",
      "Requirement already satisfied: pip in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (21.2.4)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.9.0+cu111)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (3.3.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.3.26)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (8.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (3.2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.2.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (5.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: requests in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (2.25.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.20.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.2)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (58.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<4->fastai) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from packaging->fastai) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4->fastai) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (1.26.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.21.39)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.39 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (1.24.39)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.39->boto3) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.39->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.39->boto3) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: timm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: torchvision in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from timm) (0.10.0+cu111)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from timm) (1.9.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision->timm) (8.4.0)\n",
      "Requirement already satisfied: wandb in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.12.14)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: pathtools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (5.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.5.9)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.2.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6)\n",
      "Requirement already satisfied: split-folders in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: gdown in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (3.3.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
      "Requirement already satisfied: fastai==2.5.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: fastcore==1.3.26 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.3.26)\n",
      "Requirement already satisfied: pip in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (21.2.4)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.10.0+cu111)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (2.25.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (21.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (3.2.4)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.9.0+cu111)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.24.2)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (8.4.0)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (8.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.9.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (4.62.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (58.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<4->fastai==2.5.2) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from packaging->fastai==2.5.2) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai==2.5.2) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4->fastai==2.5.2) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (1.26.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai==2.5.2) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai==2.5.2) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pandas->fastai==2.5.2) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai==2.5.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai==2.5.2) (2.2.0)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torch==1.9.0+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision==0.10.0+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision==0.10.0+cu111) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai\n",
    "!pip install boto3\n",
    "!pip install tqdm\n",
    "!pip install timm\n",
    "!pip install wandb\n",
    "!pip install split-folders\n",
    "!pip install gdown --upgrade\n",
    "!pip install fastai==2.5.2 fastcore==1.3.26\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a958421-35e9-4c25-baf5-18bea48671ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\gdown\\parse_url.py:35: UserWarning: You specified a Google Drive link that is not the correct link to download a file. You might want to try `--fuzzy` option or the following url: https://drive.google.com/uc?id=None\n",
      "  warnings.warn(\n",
      "Downloading...\n",
      "From: https://drive.google.com/drive/folders/1Q0UggEsjl2No375KHtbv-oYBmhzXn7Og?usp=sharing -O /tmp/folder --folder\n",
      "To: C:\\Users\\ArrunPersonal\\Codes\\SceneRecognition Remote Sensing\\CodeBase_Ultimate\\folder --folder\n",
      "\n",
      "0.00B [00:00, ?B/s]\n",
      "207kB [00:00, 1.81MB/s]\n",
      "453kB [00:00, 2.15MB/s]\n",
      "860kB [00:00, 2.97MB/s]\n"
     ]
    }
   ],
   "source": [
    "!gdown \"https://drive.google.com/drive/folders/1Q0UggEsjl2No375KHtbv-oYBmhzXn7Og?usp=sharing -O /tmp/folder --folder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ee677dd-5f2a-4b59-b027-59e68b3f7177",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!unzip \"C:/Users/ArrunPersonal/Codes/SceneRecognition Remote Sensing/RSI-CB256.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32e9a81-5777-4035-a8aa-0a813ee14f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da08c2b-c0bd-41d1-9312-b1482b89edc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 24717 files [01:28, 280.20 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"C:/Users/ArrunPersonal/Codes/SceneRecognition Remote Sensing/RSI-CB256\", output=\"C:/Users/ArrunPersonal/Codes/SceneRecognition Remote Sensing/RSI-CB256_splitted\",seed=42, ratio=(.8,.2), group_prefix=None, move=False) # default values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb1bd2a-96d6-4b99-8882-21e6c7297302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm\n",
    "#from fastai.distributed import *\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b81e1a-db08-4f87-b8ac-77e17a0e5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    if use_cuda: \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624c8abd-d9ff-49ae-92f0-825ac681f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, use_bn=False, first_bn=False, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [use_bn]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607f559f-ea14-4551-b477-0f6bba93f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/ArrunPersonal/Codes/SceneRecognition Remote Sensing/RSI-CB256_splitted'\n",
    "bs = 16\n",
    "sz = 64\n",
    "\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y= parent_label,\n",
    "    splitter= GrandparentSplitter(train_name = \"train\",valid_name = \"val\"))#,\n",
    "    #item_tfms=Resize(460),\n",
    "    #batch_tfms=aug_transforms(mult=1.0, do_flip=True, flip_vert=True, max_rotate=120.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=64, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d54d69-5a61-450e-989e-fe0a525dd4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Number of classes:  35\n"
     ]
    }
   ],
   "source": [
    "dls = data.dataloaders(path, bs=bs)\n",
    "print(\"Number of classes: \",dls.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036e1f5e-5019-472f-a469-286b7dc9b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"swin_base_patch4_window7_224_in22k\"\n",
    "model = timm.create_model(arch, pretrained=True, in_chans=3, num_classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99786deb-5d04-4191-9332-5a2e1dab8db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): BasicLayer(\n",
       "      dim=128, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=128\n",
       "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=256, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=256\n",
       "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=512, input_resolution=(14, 14), depth=18\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=512\n",
       "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=1024, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0bff2-3977-4e41-949b-8ceaa89fc771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict(model.named_modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b45f69-57b0-409c-a310-aae471eb8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(create_cls_module(nf=model.num_features, n_out=dls.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfdf61e-d9eb-4077-9b58-e3a869f34b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedfilename = f'{path}_{arch}'\n",
    "learn = Learner(dls, model, metrics=[accuracy,Precision(average='macro'), Recall(average='macro'), F1Score(average='macro')],  cbs=[CSVLogger(fname=savedfilename+'.csv', append=True),\n",
    "                         SaveModelCallback(monitor='valid_loss', comp=None, min_delta=0.0,fname=savedfilename, every_epoch=False, with_opt=False, reset_on_fit=True)])#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93556496-e133-4347-a776-cf60a70c0c98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet (Input shape: 16)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     16 x 64 x 128 x 128 \n",
       "Conv2d                                    9408       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 64 x 64 x 64   \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 64 x 64 x 64   \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 64 x 64  \n",
       "Conv2d                                    32768      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 32 x 32  \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    524288     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 16 x 16  \n",
       "Conv2d                                    524288     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    2097152    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Flatten                                                        \n",
       "AdaptiveAvgPool2d                                              \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 512            \n",
       "Linear                                    1049088    True      \n",
       "ReLU                                                           \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 35             \n",
       "Linear                                    17955      True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 24,575,075\n",
       "Total trainable params: 24,575,075\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x0000020AAF4AEF70>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - CSVLogger\n",
       "  - SaveModelCallback"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c25e71-b8ea-4e10-8a74-0454fd0590b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0004786300996784121)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6581d56c-6dc6-4f38-8edd-73f01ecfe7e5",
   "metadata": {},
   "source": [
    "## VGG-16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ac05219-040a-464d-97d4-7c5ff36da14d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  19\n",
      "Number of classes:  19\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "0         2.835598    2.678948    0.427184  0.393034         0.430542      0.349233  01:30     \n",
      "Better model found at epoch 0 with valid_loss value: 2.678948163986206.\n",
      "Better model found at epoch 0 with valid_loss value: 2.678948163986206.\n",
      "1         2.462350    1.411990    0.684466  0.751028         0.686615      0.679044  01:27     \n",
      "Better model found at epoch 1 with valid_loss value: 1.4119898080825806.\n",
      "Better model found at epoch 1 with valid_loss value: 1.4119898080825806.\n",
      "Better model found at epoch 2 with valid_loss value: 0.643441379070282.\n",
      "2         1.803393    0.643441    0.791262  0.831200         0.795651      0.787443  01:33     \n",
      "Better model found at epoch 2 with valid_loss value: 0.643441379070282.\n",
      "Better model found at epoch 3 with valid_loss value: 0.3560324013233185.\n",
      "3         1.256634    0.356032    0.868932  0.884300         0.872684      0.869972  01:33     \n",
      "Better model found at epoch 3 with valid_loss value: 0.3560324013233185.\n",
      "Better model found at epoch 4 with valid_loss value: 0.24193075299263.\n",
      "4         0.896229    0.241931    0.932039  0.936979         0.933511      0.932059  01:32     \n",
      "Better model found at epoch 4 with valid_loss value: 0.24193075299263.\n",
      "Better model found at epoch 5 with valid_loss value: 0.20401784777641296.\n",
      "5         0.662317    0.204018    0.927184  0.935342         0.929205      0.927617  01:29     \n",
      "Better model found at epoch 5 with valid_loss value: 0.20401784777641296.\n",
      "6         0.494583    0.207884    0.917476  0.927301         0.918599      0.917989  01:27     \n",
      "Better model found at epoch 7 with valid_loss value: 0.1774577498435974.\n",
      "7         0.383566    0.177458    0.932039  0.937811         0.935186      0.932553  01:25     \n",
      "Better model found at epoch 7 with valid_loss value: 0.1774577498435974.\n",
      "8         0.309678    0.189832    0.941748  0.948617         0.943081      0.941816  01:25     \n",
      "9         0.226802    0.140991    0.961165  0.962919         0.963097      0.961110  01:25     \n",
      "Better model found at epoch 9 with valid_loss value: 0.14099062979221344.\n",
      "Better model found at epoch 9 with valid_loss value: 0.14099062979221344.\n",
      "10        0.173185    0.126186    0.956311  0.961836         0.958392      0.956909  01:24     \n",
      "Better model found at epoch 10 with valid_loss value: 0.12618643045425415.\n",
      "Better model found at epoch 10 with valid_loss value: 0.12618643045425415.\n",
      "Better model found at epoch 11 with valid_loss value: 0.11660260707139969.\n",
      "11        0.137974    0.116603    0.966019  0.968777         0.967624      0.966394  01:25     \n",
      "Better model found at epoch 11 with valid_loss value: 0.11660260707139969.\n",
      "12        0.122608    0.128032    0.956311  0.960465         0.958392      0.956892  01:10     \n",
      "13        0.096277    0.142494    0.946602  0.951908         0.948742      0.946957  01:05     \n",
      "14        0.081406    0.128863    0.951456  0.954320         0.952809      0.950734  01:01     \n",
      "15        0.096048    0.129632    0.956311  0.961078         0.957656      0.955926  01:03     \n",
      "Better model found at epoch 16 with valid_loss value: 0.10340183228254318.\n",
      "16        0.097303    0.103402    0.966019  0.967961         0.967483      0.966299  01:04     \n",
      "Better model found at epoch 16 with valid_loss value: 0.10340183228254318.\n",
      "Better model found at epoch 17 with valid_loss value: 0.07408322393894196.\n",
      "17        0.092145    0.074083    0.975728  0.976874         0.975997      0.975327  00:59     \n",
      "Better model found at epoch 17 with valid_loss value: 0.07408322393894196.\n",
      "18        0.069664    0.111899    0.975728  0.977273         0.976396      0.975555  01:05     \n",
      "19        0.071885    0.128657    0.966019  0.969850         0.968041      0.966762  01:03     \n",
      "20        0.072706    0.095820    0.970874  0.973661         0.971212      0.971041  01:04     \n",
      "21        0.067932    0.074518    0.970874  0.973224         0.972427      0.971539  01:07     \n",
      "22        0.052687    0.098174    0.961165  0.963716         0.962778      0.961522  01:11     \n",
      "23        0.038439    0.087106    0.961165  0.965307         0.961900      0.962145  01:03     \n",
      "24        0.032355    0.151779    0.956311  0.962152         0.957993      0.957139  01:03     \n",
      "25        0.025791    0.078924    0.970874  0.973623         0.971691      0.970607  01:01     \n",
      "26        0.023057    0.088157    0.970874  0.974298         0.972089      0.971200  01:05     \n",
      "27        0.025296    0.096103    0.975728  0.978684         0.976874      0.975994  01:04     \n",
      "28        0.021231    0.098851    0.975728  0.978684         0.976874      0.975994  01:06     \n",
      "29        0.016029    0.097150    0.975728  0.978684         0.976874      0.975994  01:01     \n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_vgg16.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b703dd9d-2805-4cd0-a594-bc5984d9ea0b",
   "metadata": {},
   "source": [
    "## Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60d8c84-5f2f-46bb-8aac-b9076be3c0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  35\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "Number of classes:  35\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "THCudaCheck FAIL file=..\\torch/csrc/generic/StorageSharing.cpp line=258 error=801 : operation not supported\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ArrunPersonal\\Codes\\SceneRecognition Remote Sensing\\CodeBase_Ultimate\\arun_classifier_custom_fastai_resnet50.py\", line 68, in <module>\n",
      "    learn.fit_flat_cos(30, 3e-4)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 136, in fit_flat_cos\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 221, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 212, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 206, in _do_epoch\n",
      "    self._do_epoch_train()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 198, in _do_epoch_train\n",
      "    self._with_events(self.all_batches, 'train', CancelTrainException)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 169, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\data\\load.py\", line 109, in __iter__\n",
      "    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 918, in __init__\n",
      "    w.start()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 93, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\torch\\multiprocessing\\reductions.py\", line 247, in reduce_tensor\n",
      "    event_sync_required) = storage._share_cuda_()\n",
      "RuntimeError: cuda runtime error (801) : operation not supported at ..\\torch/csrc/generic/StorageSharing.cpp:258\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 125, in _main\n",
      "    prepare(preparation_data)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 236, in prepare\n",
      "    _fixup_main_from_path(data['init_main_from_path'])\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 287, in _fixup_main_from_path\n",
      "    main_content = runpy.run_path(main_path,\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\runpy.py\", line 268, in run_path\n",
      "    return _run_module_code(code, init_globals, run_name,\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\runpy.py\", line 97, in _run_module_code\n",
      "    _run_code(code, mod_globals, init_globals,\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\ArrunPersonal\\Codes\\SceneRecognition Remote Sensing\\CodeBase_Ultimate\\arun_classifier_custom_fastai_resnet50.py\", line 68, in <module>\n",
      "    learn.fit_flat_cos(30, 3e-4)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\callback\\schedule.py\", line 136, in fit_flat_cos\n",
      "    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 221, in fit\n",
      "    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 212, in _do_fit\n",
      "    self._with_events(self._do_epoch, 'epoch', CancelEpochException)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 206, in _do_epoch\n",
      "    self._do_epoch_train()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 198, in _do_epoch_train\n",
      "    self._with_events(self.all_batches, 'train', CancelTrainException)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 163, in _with_events\n",
      "    try: self(f'before_{event_type}');  f()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\learner.py\", line 169, in all_batches\n",
      "    for o in enumerate(self.dl): self.one_batch(*o)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\fastai\\data\\load.py\", line 109, in __iter__\n",
      "    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 918, in __init__\n",
      "    w.start()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\process.py\", line 121, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\context.py\", line 224, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\context.py\", line 327, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 45, in __init__\n",
      "    prep_data = spawn.get_preparation_data(process_obj._name)\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 154, in get_preparation_data\n",
      "    _check_not_importing_main()\n",
      "  File \"C:\\Users\\ArrunPersonal\\anaconda3\\lib\\multiprocessing\\spawn.py\", line 134, in _check_not_importing_main\n",
      "    raise RuntimeError('''\n",
      "RuntimeError: \n",
      "        An attempt has been made to start a new process before the\n",
      "        current process has finished its bootstrapping phase.\n",
      "\n",
      "        This probably means that you are not using fork to start your\n",
      "        child processes and you have forgotten to use the proper idiom\n",
      "        in the main module:\n",
      "\n",
      "            if __name__ == '__main__':\n",
      "                freeze_support()\n",
      "                ...\n",
      "\n",
      "        The \"freeze_support()\" line can be omitted if the program\n",
      "        is not going to be frozen to produce an executable.\n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_resnet50.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24a1a45-7de2-41e3-85e7-cd3a86904c61",
   "metadata": {},
   "source": [
    "## EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22e438d5-66a0-4661-b53a-33f0e378b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  31\n",
      "Number of classes:  31\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "0         2.899540    1.857604    0.696237  0.768795         0.696237      0.676077  00:43     \n",
      "Better model found at epoch 0 with valid_loss value: 1.8576041460037231.\n",
      "Better model found at epoch 0 with valid_loss value: 1.8576041460037231.\n",
      "Better model found at epoch 1 with valid_loss value: 0.4419417381286621.\n",
      "1         1.570499    0.441942    0.884409  0.894951         0.884409      0.883893  00:44     \n",
      "Better model found at epoch 1 with valid_loss value: 0.4419417381286621.\n",
      "2         0.930453    0.303775    0.930108  0.939273         0.930108      0.930006  00:44     \n",
      "Better model found at epoch 2 with valid_loss value: 0.30377528071403503.\n",
      "Better model found at epoch 2 with valid_loss value: 0.30377528071403503.\n",
      "3         0.531346    0.240020    0.927419  0.936796         0.927419      0.928031  00:43     \n",
      "Better model found at epoch 3 with valid_loss value: 0.2400200515985489.\n",
      "Better model found at epoch 3 with valid_loss value: 0.2400200515985489.\n",
      "4         0.346789    0.254439    0.927419  0.936040         0.927419      0.926321  00:44     \n",
      "5         0.249092    0.262363    0.911290  0.918398         0.911290      0.909947  00:41     \n",
      "6         0.193313    0.251089    0.919355  0.926086         0.919355      0.920299  00:41     \n",
      "7         0.145525    0.253897    0.932796  0.939044         0.932796      0.932961  00:43     \n",
      "8         0.159643    0.297897    0.924731  0.931802         0.924731      0.924438  00:40     \n",
      "9         0.141773    0.381798    0.913979  0.927357         0.913978      0.914106  00:43     \n",
      "Better model found at epoch 10 with valid_loss value: 0.21291488409042358.\n",
      "10        0.113211    0.212915    0.935484  0.940648         0.935484      0.935863  00:40     \n",
      "Better model found at epoch 10 with valid_loss value: 0.21291488409042358.\n",
      "11        0.089869    0.286384    0.916667  0.922801         0.916667      0.915959  00:41     \n",
      "12        0.110099    0.277705    0.922043  0.931358         0.922043      0.921411  00:42     \n",
      "13        0.103183    0.340744    0.930108  0.937487         0.930108      0.929064  00:42     \n",
      "14        0.105381    0.402379    0.932796  0.937872         0.932796      0.932473  00:44     \n",
      "15        0.089432    0.306467    0.940860  0.948133         0.940860      0.940881  00:42     \n",
      "16        0.078259    0.332911    0.935484  0.942811         0.935484      0.935608  00:41     \n",
      "17        0.072424    0.258264    0.927419  0.931771         0.927419      0.927218  00:41     \n",
      "18        0.071941    0.245894    0.948925  0.954222         0.948925      0.949019  00:42     \n",
      "19        0.058084    0.342810    0.932796  0.938113         0.932796      0.932130  00:41     \n",
      "20        0.051231    0.404912    0.924731  0.933068         0.924731      0.924104  00:40     \n",
      "21        0.051514    0.388273    0.924731  0.931447         0.924731      0.923923  00:42     \n",
      "22        0.043260    0.295724    0.938172  0.943540         0.938172      0.937474  00:41     \n",
      "23        0.050635    0.231621    0.940860  0.943452         0.940860      0.940388  00:40     \n",
      "24        0.037209    0.284950    0.935484  0.940496         0.935484      0.935219  00:40     \n",
      "25        0.035342    0.328232    0.935484  0.939602         0.935484      0.934496  00:43     \n",
      "26        0.029003    0.324304    0.935484  0.939960         0.935484      0.934371  00:44     \n",
      "27        0.026552    0.295633    0.940860  0.945076         0.940860      0.940518  00:44     \n",
      "28        0.024340    0.273687    0.938172  0.943215         0.938172      0.938036  00:42     \n",
      "29        0.017656    0.259167    0.946237  0.950165         0.946237      0.946381  00:41     \n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_effncientnet_b3.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa378083-e862-4a04-9a53-7b82ea326030",
   "metadata": {},
   "source": [
    "## ViT Base 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6a556e6-8bdd-4748-a7f8-c2cf1e04b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  31\n",
      "Number of classes:  31\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "Better model found at epoch 0 with valid_loss value: 1.1279934644699097.\n",
      "0         2.320258    1.127993    0.698925  0.776386         0.698925      0.676866  01:36     \n",
      "Better model found at epoch 0 with valid_loss value: 1.1279934644699097.\n",
      "1         0.917351    0.489750    0.849462  0.891960         0.849462      0.838392  01:33     \n",
      "Better model found at epoch 1 with valid_loss value: 0.4897502064704895.\n",
      "Better model found at epoch 1 with valid_loss value: 0.4897502064704895.\n",
      "2         0.382679    0.264705    0.924731  0.940174         0.924731      0.923400  01:33     \n",
      "Better model found at epoch 2 with valid_loss value: 0.26470547914505005.\n",
      "Better model found at epoch 2 with valid_loss value: 0.26470547914505005.\n",
      "Better model found at epoch 3 with valid_loss value: 0.18886975944042206.\n",
      "3         0.207155    0.188870    0.943548  0.948784         0.943548      0.942286  01:32     \n",
      "Better model found at epoch 3 with valid_loss value: 0.18886975944042206.\n",
      "4         0.129506    0.238000    0.932796  0.943444         0.932796      0.932573  01:33     \n",
      "5         0.112204    0.174466    0.956989  0.961404         0.956989      0.956931  01:34     \n",
      "Better model found at epoch 5 with valid_loss value: 0.17446576058864594.\n",
      "Better model found at epoch 5 with valid_loss value: 0.17446576058864594.\n",
      "6         0.088562    0.341259    0.919355  0.938209         0.919355      0.918671  01:33     \n",
      "7         0.052948    0.214505    0.954301  0.958456         0.954301      0.953684  01:31     \n",
      "8         0.070007    0.294111    0.935484  0.948564         0.935484      0.935119  01:32     \n",
      "9         0.115012    0.234164    0.948925  0.955410         0.948925      0.948936  01:31     \n",
      "10        0.075676    0.241264    0.948925  0.955648         0.948925      0.949304  01:34     \n",
      "11        0.069018    0.521886    0.879032  0.894557         0.879032      0.876085  01:33     \n",
      "12        0.067184    0.229964    0.938172  0.943297         0.938172      0.936909  01:33     \n",
      "13        0.026881    0.297453    0.935484  0.941281         0.935484      0.934500  01:32     \n",
      "14        0.091714    0.263826    0.938172  0.942042         0.938172      0.937377  01:40     \n",
      "15        0.063249    0.235798    0.954301  0.960030         0.954301      0.954554  01:42     \n",
      "16        0.107821    0.238588    0.946237  0.950923         0.946237      0.945708  01:41     \n",
      "17        0.046946    0.264937    0.948925  0.953072         0.948925      0.948121  01:42     \n",
      "18        0.048158    0.293616    0.943548  0.947641         0.943548      0.942501  01:44     \n",
      "19        0.019839    0.283814    0.938172  0.942924         0.938172      0.936720  01:42     \n",
      "^Coch 21/30 : |--------------------| 0.00% [0/93 00:00<00:00]\n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_vit_base_patch16_224.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f36107-996d-4811-b65e-62f7f1c49ec7",
   "metadata": {},
   "source": [
    "## Swin_base_224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c713cc69-9c81-4ee5-a84b-a05a2eedbce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  31\n",
      "Number of classes:  31\n",
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth\" to /home/.cache/torch/hub/checkpoints/swin_base_patch4_window7_224_22k.pth\n",
      "Downloading: \"https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window7_224_22k.pth\" to /home/.cache/torch/hub/checkpoints/swin_base_patch4_window7_224_22k.pth\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "0         2.911164    1.971535    0.666667  0.746425         0.666667      0.656205  00:56     \n",
      "Better model found at epoch 0 with valid_loss value: 1.9715346097946167.\n",
      "Better model found at epoch 0 with valid_loss value: 1.9715346097946167.\n",
      "Better model found at epoch 1 with valid_loss value: 0.6243441700935364.\n",
      "1         1.515444    0.624344    0.884409  0.899156         0.884409      0.884867  00:56     \n",
      "Better model found at epoch 1 with valid_loss value: 0.6243441700935364.\n",
      "Better model found at epoch 2 with valid_loss value: 0.3570367991924286.\n",
      "2         0.781376    0.357037    0.900538  0.907991         0.900538      0.897951  00:54     \n",
      "Better model found at epoch 2 with valid_loss value: 0.3570367991924286.\n",
      "Better model found at epoch 3 with valid_loss value: 0.2806761562824249.\n",
      "3         0.434675    0.280676    0.922043  0.929061         0.922043      0.922156  00:59     \n",
      "Better model found at epoch 3 with valid_loss value: 0.2806761562824249.\n",
      "4         0.249443    0.235666    0.930108  0.942785         0.930108      0.930069  00:55     \n",
      "Better model found at epoch 4 with valid_loss value: 0.23566599190235138.\n",
      "Better model found at epoch 4 with valid_loss value: 0.23566599190235138.\n",
      "5         0.169807    0.163082    0.951613  0.956459         0.951613      0.951416  00:55     \n",
      "Better model found at epoch 5 with valid_loss value: 0.1630815863609314.\n",
      "Better model found at epoch 5 with valid_loss value: 0.1630815863609314.\n",
      "6         0.121774    0.201700    0.951613  0.956576         0.951613      0.951264  00:53     \n",
      "7         0.107937    0.258520    0.935484  0.947489         0.935484      0.933889  00:57     \n",
      "8         0.089865    0.229773    0.932796  0.945296         0.932796      0.933152  00:57     \n",
      "9         0.075247    0.271679    0.911290  0.925421         0.911290      0.908560  00:54     \n",
      "10        0.053301    0.152446    0.956989  0.959484         0.956989      0.956999  00:55     \n",
      "Better model found at epoch 10 with valid_loss value: 0.15244625508785248.\n",
      "Better model found at epoch 10 with valid_loss value: 0.15244625508785248.\n",
      "11        0.072261    0.191291    0.943548  0.949982         0.943548      0.943381  00:51     \n",
      "12        0.049604    0.256587    0.938172  0.948740         0.938172      0.937501  00:59     \n",
      "13        0.063338    0.203008    0.951613  0.955855         0.951613      0.948507  00:55     \n",
      "14        0.026417    0.190572    0.962366  0.965804         0.962366      0.961899  00:53     \n",
      "15        0.014702    0.199511    0.962366  0.965950         0.962366      0.962163  00:52     \n",
      "16        0.016274    0.170362    0.956989  0.961211         0.956989      0.956974  00:54     \n",
      "17        0.058374    0.329468    0.927419  0.941535         0.927419      0.927278  00:54     \n",
      "18        0.054362    0.178807    0.954301  0.955880         0.954301      0.954357  00:53     \n",
      "19        0.019751    0.271843    0.938172  0.944051         0.938172      0.937138  00:56     \n",
      "20        0.018447    0.266128    0.938172  0.946260         0.938172      0.937270  00:53     \n",
      "21        0.043439    0.185786    0.954301  0.958163         0.954301      0.954589  00:55     \n",
      "22        0.027683    0.217061    0.951613  0.956958         0.951613      0.951218  00:53     \n",
      "23        0.029670    0.279525    0.943548  0.951389         0.943548      0.942015  00:54     \n",
      "24        0.020351    0.291473    0.935484  0.942703         0.935484      0.934154  00:54     \n",
      "25        0.005934    0.231520    0.948925  0.950532         0.948925      0.948391  00:55     \n",
      "26        0.011393    0.247905    0.951613  0.956696         0.951613      0.951198  00:56     \n",
      "27        0.004331    0.208406    0.956989  0.960025         0.956989      0.956676  00:55     \n",
      "28        0.003210    0.206563    0.954301  0.957337         0.954301      0.953988  00:55     \n",
      "29        0.003003    0.207028    0.954301  0.957337         0.954301      0.953988  00:57     \n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_swin_base.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3151705d-9bc7-4308-a4be-87d5cf1baf4c",
   "metadata": {},
   "source": [
    "## ConvNextBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "071b89cd-ec7b-4a4b-9978-3fa98315690c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes:  31\n",
      "Number of classes:  31\n",
      "epoch     train_loss  valid_loss  accuracy  precision_score  recall_score  f1_score  time    \n",
      "[W reducer.cpp:283] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [1536, 1, 7, 7], strides() = [49, 1, 7, 1]\n",
      "bucket_view.sizes() = [1536, 1, 7, 7], strides() = [49, 49, 7, 1] (function operator())\n",
      "[W reducer.cpp:283] Warning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\n",
      "grad.sizes() = [1536, 1, 7, 7], strides() = [49, 1, 7, 1]\n",
      "bucket_view.sizes() = [1536, 1, 7, 7], strides() = [49, 49, 7, 1] (function operator())\n",
      "Better model found at epoch 0 with valid_loss value: 2.707974433898926.\n",
      "0         3.101981    2.707974    0.693548  0.734530         0.693548      0.660245  01:34     \n",
      "Better model found at epoch 0 with valid_loss value: 2.707974433898926.\n",
      "1         2.149865    1.456018    0.879032  0.896757         0.879032      0.876952  01:31     \n",
      "Better model found at epoch 1 with valid_loss value: 1.4560176134109497.\n",
      "Better model found at epoch 1 with valid_loss value: 1.4560176134109497.\n",
      "Better model found at epoch 2 with valid_loss value: 0.704457700252533.\n",
      "2         1.193718    0.704458    0.911290  0.922450         0.911290      0.910436  01:34     \n",
      "Better model found at epoch 2 with valid_loss value: 0.704457700252533.\n",
      "Better model found at epoch 3 with valid_loss value: 0.43248239159584045.\n",
      "3         0.635866    0.432482    0.932796  0.940521         0.932796      0.933184  01:33     \n",
      "Better model found at epoch 3 with valid_loss value: 0.43248239159584045.\n",
      "4         0.329077    0.271366    0.938172  0.946689         0.938172      0.936998  01:32     \n",
      "Better model found at epoch 4 with valid_loss value: 0.271366149187088.\n",
      "Better model found at epoch 4 with valid_loss value: 0.271366149187088.\n",
      "Better model found at epoch 5 with valid_loss value: 0.19419175386428833.\n",
      "5         0.167554    0.194192    0.951613  0.954963         0.951613      0.951271  01:34     \n",
      "Better model found at epoch 5 with valid_loss value: 0.19419175386428833.\n",
      "6         0.111096    0.212239    0.943548  0.950975         0.943548      0.942467  01:35     \n",
      "7         0.065818    0.205908    0.938172  0.943903         0.938172      0.937971  01:36     \n",
      "Better model found at epoch 8 with valid_loss value: 0.174831822514534.\n",
      "8         0.041252    0.174832    0.954301  0.957574         0.954301      0.953626  01:35     \n",
      "Better model found at epoch 8 with valid_loss value: 0.174831822514534.\n",
      "9         0.020689    0.159086    0.951613  0.956493         0.951613      0.950478  01:35     \n",
      "Better model found at epoch 9 with valid_loss value: 0.15908591449260712.\n",
      "Better model found at epoch 9 with valid_loss value: 0.15908591449260712.\n",
      "Better model found at epoch 10 with valid_loss value: 0.15147729218006134.\n",
      "10        0.011358    0.151477    0.959677  0.963713         0.959677      0.959186  01:35     \n",
      "Better model found at epoch 10 with valid_loss value: 0.15147729218006134.\n",
      "11        0.012186    0.195911    0.930108  0.941126         0.930108      0.927656  01:36     \n",
      "12        0.059677    0.178659    0.951613  0.957314         0.951613      0.951970  01:32     \n",
      "13        0.036843    0.238672    0.943548  0.951820         0.943548      0.939772  01:34     \n",
      "14        0.026667    0.170109    0.959677  0.966657         0.959677      0.959584  01:35     \n",
      "15        0.008304    0.169795    0.954301  0.959033         0.954301      0.953907  01:34     \n",
      "16        0.003661    0.150063    0.962366  0.964831         0.962366      0.962495  01:32     \n",
      "Better model found at epoch 16 with valid_loss value: 0.15006309747695923.\n",
      "Better model found at epoch 16 with valid_loss value: 0.15006309747695923.\n",
      "17        0.002175    0.184350    0.956989  0.961404         0.956989      0.956618  01:34     \n",
      "18        0.006831    0.482230    0.911290  0.908704         0.911290      0.899611  01:32     \n",
      "19        0.015944    0.201561    0.946237  0.949562         0.946237      0.945518  01:37     \n",
      "20        0.017586    0.156706    0.962366  0.965950         0.962366      0.961762  01:32     \n",
      "21        0.004740    0.145960    0.965054  0.967645         0.965054      0.964804  01:34     \n",
      "Better model found at epoch 21 with valid_loss value: 0.14596019685268402.\n",
      "Better model found at epoch 21 with valid_loss value: 0.14596019685268402.\n",
      "22        0.002084    0.154443    0.959677  0.962417         0.959677      0.959419  01:34     \n",
      "23        0.001279    0.153763    0.967742  0.969772         0.967742      0.967671  01:32     \n",
      "24        0.012845    0.169317    0.965054  0.967476         0.965054      0.964818  01:35     \n",
      "25        0.003070    0.159311    0.954301  0.957247         0.954301      0.953637  01:33     \n",
      "26        0.001654    0.162536    0.956989  0.960280         0.956989      0.956531  01:33     \n",
      "27        0.001018    0.162378    0.959677  0.962623         0.959677      0.959287  01:33     \n",
      "28        0.000791    0.163760    0.959677  0.962623         0.959677      0.959287  01:32     \n",
      "29        0.000650    0.164096    0.959677  0.962623         0.959677      0.959287  01:33     \n"
     ]
    }
   ],
   "source": [
    "!python -m fastai.launch \"arun_classifier_custom_fastai_convnext.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb5b042-f47d-4e4b-9769-67c394a54b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"swin*\",pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bbe389-d2a8-413f-b34b-f55b1d51bf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"convnext*\",pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ecf648-59c5-4b84-9fda-d290fca3cc37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
